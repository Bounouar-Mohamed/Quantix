/**
 * Service pour g√©rer les threads OpenAI Assistants
 * Unifie chat REST et Realtime via assistant_thread_id
 * 
 * PR√âPARATION MIGRATION : Ce service utilisera bient√¥t AssistantAdapter
 * pour supporter Responses API + MCP. Actuellement utilise l'API legacy.
 */

import { Injectable, Logger, BadRequestException } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import OpenAI from 'openai';
import { prisma } from '../../db/prisma';
import { executeTool } from '../toolRegistry';
import { profileJohn } from '../modelProfile';
import { AssistantAdapter } from '../interfaces/assistant-adapter.interface';
import { LegacyAssistantAdapter } from '../adapters/legacy-assistant.adapter';

@Injectable()
export class AssistantsService {
    private readonly logger = new Logger(AssistantsService.name);
    private openai: OpenAI;

    constructor(private readonly configService: ConfigService) {
        const apiKey = process.env.OPENAI_API_KEY || this.configService.get<string>('OPENAI_API_KEY');
        if (!apiKey) {
            throw new Error('OPENAI_API_KEY manquante');
        }
        this.openai = new OpenAI({ apiKey });
    }

    /**
     * Cr√©er ou r√©cup√©rer un thread pour une conversation (multi-tenant)
     */
    async upsertThread(
        conversationId: string,
        tenantId?: string,
        assistantId?: string
    ): Promise<string> {
        // Prisma n'accepte pas null dans les contraintes uniques composites
        // Utiliser 'global' comme valeur par d√©faut si tenantId est absent
        const normalizedTenantId = tenantId || 'global';

        this.logger.log(`üîç [THREAD] Recherche thread pour conversationId: ${conversationId}, tenantId: ${normalizedTenantId}`);

        // Chercher un thread existant avec contrainte multi-tenant
        const existing = await prisma.conversationThread.findUnique({
            where: {
                tenantId_conversationId: {
                    tenantId: normalizedTenantId,
                    conversationId,
                },
            },
        });

        if (existing) {
            this.logger.log(
                `‚úÖ [THREAD] Thread EXISTANT trouv√©: ${existing.assistantThreadId} pour conversationId: ${conversationId}, tenantId: ${normalizedTenantId}`
            );
            
            // V√©rifier combien de messages sont dans ce thread
            try {
                const messages = await this.openai.beta.threads.messages.list(existing.assistantThreadId, { limit: 10 });
                this.logger.log(`üìä [THREAD] Thread ${existing.assistantThreadId} contient ${messages.data.length} messages`);
            } catch (err: any) {
                this.logger.warn(`‚ö†Ô∏è [THREAD] Impossible de v√©rifier les messages du thread: ${err.message}`);
            }
            
            return existing.assistantThreadId;
        }

        // Cr√©er un nouveau thread OpenAI
        this.logger.log(
            `üÜï [THREAD] CR√âATION nouveau thread pour conversationId: ${conversationId}, tenantId: ${normalizedTenantId}`
        );
        const thread = await this.openai.beta.threads.create();

        // Stocker le mapping avec tenantId (utiliser 'global' si absent)
        await prisma.conversationThread.create({
            data: {
                conversationId,
                tenantId: normalizedTenantId,
                assistantThreadId: thread.id,
                assistantId: assistantId || undefined,
            },
        });

        this.logger.log(`‚úÖ [THREAD] Thread cr√©√©: ${thread.id} pour conversationId: ${conversationId}, tenantId: ${normalizedTenantId}`);
        return thread.id;
    }

    /**
     * Ajouter un message au thread (avec d√©duplication optionnelle par eventId)
     */
    async addMessage(
        threadId: string,
        role: 'user' | 'assistant',
        content: string,
        options?: { eventId?: string; meta?: any }
    ): Promise<void> {
        try {
            // D√©duplication : v√©rifier si eventId existe d√©j√† (via table EventUsage ou cache)
            if (options?.eventId) {
                // TODO: Impl√©menter d√©duplication via EventUsage ou cache Redis
                // Pour l'instant, on log seulement
                this.logger.debug(`Message avec eventId: ${options.eventId}`);
            }

            const contentPreview = content.length > 100 ? content.substring(0, 100) + '...' : content;
            this.logger.log(`üìù [MESSAGE] Ajout message ${role} au thread ${threadId}: "${contentPreview}"`);

            await this.openai.beta.threads.messages.create(threadId, {
                role,
                content,
            });
            
            this.logger.log(`‚úÖ [MESSAGE] Message ${role} ajout√© avec succ√®s au thread ${threadId}${options?.eventId ? ` (eventId: ${options.eventId})` : ''}`);
            
            // V√©rifier que le message est bien dans le thread
            try {
                const messages = await this.openai.beta.threads.messages.list(threadId, { limit: 5 });
                const messageCount = messages.data.length;
                this.logger.log(`üìä [MESSAGE] Thread ${threadId} contient maintenant ${messageCount} messages au total`);
            } catch (err: any) {
                this.logger.warn(`‚ö†Ô∏è [MESSAGE] Impossible de v√©rifier le nombre de messages: ${err.message}`);
            }
        } catch (error: any) {
            this.logger.error(`‚ùå [MESSAGE] Erreur ajout message au thread ${threadId}:`, error);
            throw new BadRequestException(`Impossible d'ajouter le message: ${error.message}`);
        }
    }

    /**
     * Ex√©cuter un run et attendre la r√©ponse
     */
    async runAndPoll(
        threadId: string,
        assistantId: string,
        userId?: string
    ): Promise<string> {
        // V√©rifier les messages existants dans le thread avant de lancer le run
        try {
            const messagesBefore = await this.openai.beta.threads.messages.list(threadId, { limit: 20 });
            this.logger.log(`üìã [RUN] Thread ${threadId} contient ${messagesBefore.data.length} messages avant le run`);
            if (messagesBefore.data.length > 0) {
                // Afficher les 5 derniers messages pour voir le contexte complet
                const lastMessages = messagesBefore.data.slice(0, 5).map((m, idx) => {
                    const content = m.content[0];
                    const text = content.type === 'text' ? content.text.value : content.type;
                    const preview = text.length > 80 ? text.substring(0, 80) + '...' : text;
                    return `  ${idx + 1}. [${m.role}] ${preview}`;
                });
                this.logger.log(`üìã [RUN] Contexte conversationnel (5 derniers messages):\n${lastMessages.join('\n')}`);
                
                // Compter user vs assistant pour v√©rifier la structure
                const userCount = messagesBefore.data.filter(m => m.role === 'user').length;
                const assistantCount = messagesBefore.data.filter(m => m.role === 'assistant').length;
                this.logger.log(`üìä [RUN] R√©partition: ${userCount} messages user, ${assistantCount} messages assistant`);
            }
        } catch (err: any) {
            this.logger.warn(`‚ö†Ô∏è [RUN] Impossible de lire les messages avant run: ${err.message}`);
        }

        // Cr√©er le run
        this.logger.log(`üöÄ [RUN] Cr√©ation run pour thread ${threadId} avec assistant ${assistantId}`);
        let run = await this.openai.beta.threads.runs.create(threadId, {
            assistant_id: assistantId,
        });

        this.logger.log(`‚úÖ [RUN] Run cr√©√©: ${run.id} pour thread ${threadId}`);

        // Polling jusqu'√† completion
        while (true) {
            run = await this.openai.beta.threads.runs.retrieve(threadId, run.id);

            if (run.status === 'completed') {
                this.logger.log(`‚úÖ [RUN] Run ${run.id} TERMIN√â avec succ√®s`);
                
                // V√©rifier les messages apr√®s completion
                try {
                    const messagesAfter = await this.openai.beta.threads.messages.list(threadId, { limit: 10 });
                    this.logger.log(`üìä [RUN] Thread ${threadId} contient maintenant ${messagesAfter.data.length} messages apr√®s run`);
                } catch (err: any) {
                    this.logger.warn(`‚ö†Ô∏è [RUN] Impossible de v√©rifier messages apr√®s completion: ${err.message}`);
                }
                
                break;
            }

            if (run.status === 'requires_action') {
                // Ex√©cuter les tool calls
                const toolCalls = run.required_action?.submit_tool_outputs?.tool_calls || [];
                const toolOutputs: Array<{ tool_call_id: string; output: string }> = [];

                for (const toolCall of toolCalls) {
                    try {
                        const functionName = toolCall.function.name;
                        const argsStr = toolCall.function.arguments || '{}';
                        const args = JSON.parse(argsStr);

                        this.logger.log(`üîß [TOOL] Ex√©cution tool: ${functionName}`);
                        
                        let output: any;
                        
                        // V√©rifier si la function existe dans le toolRegistry
                        try {
                            output = await executeTool(functionName, args, {
                                userId: userId || 'anonymous',
                            });
                            this.logger.log(`‚úÖ [TOOL] Tool ${functionName} ex√©cut√© avec succ√®s`);
                        } catch (toolError: any) {
                            // Si la function n'existe pas dans toolRegistry
                            if (toolError.message?.includes('not found')) {
                                this.logger.warn(`‚ö†Ô∏è [TOOL] Tool ${functionName} non trouv√© dans toolRegistry`);
                                this.logger.warn(`‚ö†Ô∏è [TOOL] Si c'est une serverless function OpenAI, elle devrait s'ex√©cuter automatiquement`);
                                this.logger.warn(`‚ö†Ô∏è [TOOL] Sinon, vous devez l'ajouter dans toolRegistry.ts ou cr√©er un endpoint personnalis√©`);
                                
                                // Retourner une erreur claire
                                throw new Error(`Function ${functionName} n'est pas impl√©ment√©e dans le backend. Ajoutez-la dans toolRegistry.ts ou configurez-la comme serverless function sur OpenAI.`);
                            }
                            throw toolError;
                        }

                        toolOutputs.push({
                            tool_call_id: toolCall.id,
                            output: JSON.stringify(output),
                        });
                    } catch (error: any) {
                        this.logger.error(`‚ùå [TOOL] Erreur tool ${toolCall.id}:`, error);
                        toolOutputs.push({
                            tool_call_id: toolCall.id,
                            output: JSON.stringify({ error: error.message || 'tool_error' }),
                        });
                    }
                }

                // Soumettre les outputs
                await this.openai.beta.threads.runs.submitToolOutputs(threadId, run.id, {
                    tool_outputs: toolOutputs,
                });

                this.logger.log(`Tool outputs soumis pour run ${run.id}`);
                // Continuer le polling
                await new Promise((resolve) => setTimeout(resolve, 800));
                continue;
            }

            if (['failed', 'cancelled', 'expired'].includes(run.status)) {
                const error = (run as any).last_error;
                const errorMsg = error?.message || run.status;
                const errorCode = error?.code || 'unknown';
                const errorType = error?.type || 'unknown';
                
                this.logger.error(`Run ${run.id} √©chou√©: ${errorMsg} (code: ${errorCode}, type: ${errorType})`);
                
                // Log d√©taill√© pour debug
                this.logger.error(`D√©tails erreur run: ${JSON.stringify(error, null, 2)}`);
                
                // Si c'est une erreur r√©cup√©rable, on peut throw avec plus de contexte
                throw new BadRequestException(`Run √©chou√©: ${errorMsg}`);
            }

            // Attendre avant de re-poll
            await new Promise((resolve) => setTimeout(resolve, 800));
        }

        // R√©cup√©rer le dernier message assistant
        this.logger.log(`üì• [RUN] R√©cup√©ration dernier message assistant du thread ${threadId}`);
        const messages = await this.openai.beta.threads.messages.list(threadId, {
            order: 'desc',
            limit: 1,
        });

        this.logger.log(`üìä [RUN] Total messages dans thread: ${messages.data.length}`);

        const lastMessage = messages.data[0];
        if (!lastMessage || lastMessage.role !== 'assistant') {
            this.logger.error(`‚ùå [RUN] Aucun message assistant trouv√©. Dernier message: ${lastMessage ? lastMessage.role : 'null'}`);
            throw new BadRequestException('Aucun message assistant trouv√©');
        }

        const content = lastMessage.content[0];
        if (content.type === 'text') {
            const answerText = content.text.value;
            const preview = answerText.length > 100 ? answerText.substring(0, 100) + '...' : answerText;
            this.logger.log(`‚úÖ [RUN] R√©ponse r√©cup√©r√©e (${answerText.length} chars): "${preview}"`);
            return answerText;
        }

        this.logger.error(`‚ùå [RUN] Format de r√©ponse non support√©: ${content.type}`);
        throw new BadRequestException('Format de r√©ponse non support√©');
    }

    /**
     * R√©cup√©rer les messages d'un thread (pour alimenter Chat Completions avec l'historique)
     */
    async getThreadMessages(threadId: string, limit: number = 20): Promise<Array<{ role: 'user' | 'assistant' | 'system'; content: string }>> {
        try {
            this.logger.log(`üìö [THREAD] R√©cup√©ration messages du thread ${threadId} (limit: ${limit})`);
            const messages = await this.openai.beta.threads.messages.list(threadId, {
                order: 'asc', // Ordre chronologique
                limit,
            });

            const formattedMessages: Array<{ role: 'user' | 'assistant' | 'system'; content: string }> = [];
            
            for (const msg of messages.data) {
                const content = msg.content[0];
                if (content.type === 'text') {
                    formattedMessages.push({
                        role: msg.role as 'user' | 'assistant' | 'system',
                        content: content.text.value,
                    });
                }
            }

            this.logger.log(`‚úÖ [THREAD] ${formattedMessages.length} messages r√©cup√©r√©s du thread ${threadId}`);
            return formattedMessages;
        } catch (error: any) {
            this.logger.error(`‚ùå [THREAD] Erreur r√©cup√©ration messages du thread ${threadId}:`, error);
            throw new BadRequestException(`Impossible de r√©cup√©rer les messages du thread: ${error.message}`);
        }
    }

    /**
     * R√©cup√©rer les instructions et tools d'un assistant (pour Realtime)
     */
    async getAssistantConfig(assistantId?: string): Promise<{ instructions: string; tools?: any[] }> {
        const id = assistantId || process.env.OPENAI_ASSISTANT_ID;
        
        if (!id) {
            // Fallback sur profileJohn si pas d'assistant configur√©
            this.logger.log(`‚ö†Ô∏è [ASSISTANT] Pas d'assistant configur√©, utilisation profileJohn`);
            return {
                instructions: profileJohn.instructions,
                tools: profileJohn.tools.map(t => ({
                    type: 'function' as const,
                    function: {
                        name: t.name,
                        description: t.description,
                        parameters: t.parameters,
                    },
                })),
            };
        }

        try {
            this.logger.log(`üì• [ASSISTANT] R√©cup√©ration config assistant: ${id}`);
            const assistant = await this.openai.beta.assistants.retrieve(id);
            
            this.logger.log(`‚úÖ [ASSISTANT] Assistant r√©cup√©r√©: ${assistant.name || 'sans nom'} (${id})`);
            this.logger.log(`üìù [ASSISTANT] Instructions: ${assistant.instructions?.substring(0, 100)}...`);
            this.logger.log(`üîß [ASSISTANT] Tools: ${assistant.tools?.length || 0} tools configur√©s`);
            
            return {
                instructions: assistant.instructions || profileJohn.instructions,
                tools: assistant.tools || [],
            };
        } catch (error: any) {
            this.logger.error(`‚ùå [ASSISTANT] Erreur r√©cup√©ration assistant ${id}: ${error.message}`);
            this.logger.warn(`‚ö†Ô∏è [ASSISTANT] Fallback sur profileJohn`);
            
            // Fallback sur profileJohn en cas d'erreur
            return {
                instructions: profileJohn.instructions,
                tools: profileJohn.tools.map(t => ({
                    type: 'function' as const,
                    function: {
                        name: t.name,
                        description: t.description,
                        parameters: t.parameters,
                    },
                })),
            };
        }
    }

    /**
     * Obtenir l'assistant_id depuis le profil (ou cr√©er un assistant si n√©cessaire)
     */
    async getOrCreateAssistant(): Promise<string> {
        // Pour l'instant, on utilise un assistant_id configur√© ou on en cr√©e un
        // TODO: G√©rer la cr√©ation/persistance d'assistant depuis profileJohn
        const assistantId = process.env.OPENAI_ASSISTANT_ID;
        if (assistantId) {
            this.logger.log(`‚úÖ [ASSISTANT] Utilisation assistant configur√©: ${assistantId}`);
            return assistantId;
        }

        // Si pas d'assistant_id configur√©, cr√©er un assistant depuis le profil
        this.logger.log('Cr√©ation assistant depuis profileJohn');
        
        // IMPORTANT: Les tools sont d√©finis comme "function" dans Assistants API
        // Ils seront ex√©cut√©s via requires_action ‚Üí executeTool() dans runAndPoll()
        // Le code g√®re d√©j√† requires_action, donc on peut activer les tools
        const tools = profileJohn.tools.map(t => ({
            type: 'function' as const,
            function: {
                name: t.name,
                description: t.description,
                parameters: t.parameters,
            },
        }));
        
        this.logger.log(`üîß [ASSISTANT] Activation de ${tools.length} tools: ${tools.map(t => t.function.name).join(', ')}`);
        
        try {
            const assistant = await this.openai.beta.assistants.create({
                name: 'John',
                instructions: profileJohn.instructions,
                model: process.env.OPENAI_MODEL_TEXT || 'gpt-4o-mini',
                tools, // Tools activ√©s - seront ex√©cut√©s via requires_action
                temperature: profileJohn.temperature,
            });

            this.logger.log(`‚úÖ [ASSISTANT] Assistant cr√©√©: ${assistant.id} (√† configurer dans OPENAI_ASSISTANT_ID)`);
            this.logger.log(`‚úÖ [ASSISTANT] Tools activ√©s: ${tools.length} functions disponibles`);
            return assistant.id;
        } catch (error: any) {
            this.logger.error(`Erreur cr√©ation assistant: ${error.message}`);
            throw error;
        }
    }

    /**
     * R√©cup√©rer le thread_id depuis conversationId (multi-tenant)
     */
    async getThreadId(conversationId: string, tenantId?: string): Promise<string | null> {
        // Prisma n'accepte pas null dans les contraintes uniques composites
        const normalizedTenantId = tenantId || 'global';
        
        const thread = await prisma.conversationThread.findUnique({
            where: {
                tenantId_conversationId: {
                    tenantId: normalizedTenantId,
                    conversationId,
                },
            },
        });
        return thread?.assistantThreadId || null;
    }
}

